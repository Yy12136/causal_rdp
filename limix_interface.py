"""
ä¸ LimiX-ldm çš„å¯¹æ¥æ¥å£ï¼ˆé€»è¾‘å› æœå…ˆéªŒï¼‰ã€‚

æ ¸å¿ƒé€»è¾‘ï¼š
- yaml åªæä¾›ç¡¬çº¦æŸï¼ˆblacklist/whitelistï¼‰ï¼š"ä¸€å®šä¸ä¼šå‡ºç°çš„è¾¹" / "ä¸€å®šä¼šå­˜åœ¨çš„è¾¹"
- LimiX å®˜æ–¹æ¨¡å‹åŸºäºæ•°æ®å­¦ä¹  soft priorï¼ˆedge_prefï¼‰ï¼š
  - r_* -> score çš„ soft priorï¼šé€šè¿‡ LimiX å›å½’ score å¾—åˆ°ç‰¹å¾é‡è¦æ€§
  - r_i -> r_j çš„ soft priorï¼šé€šè¿‡ r_* ä¹‹é—´çš„ç›¸å…³æ€§å¾—åˆ°
- DAGMA-MLP åªä½¿ç”¨ LimiX å­¦å‡ºæ¥çš„ soft priorï¼Œä¸å†ä½¿ç”¨ yaml ä¸­çš„ soft_edges
"""

from __future__ import annotations

from dataclasses import dataclass
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np
import yaml
import pandas as pd
import torch
import sys


Edge = Tuple[str, str]  # (parent, child)


@dataclass
class LimixConstraints:
    """
    LimiX è¾“å‡º/ä¼ é€’ç»™ DAGMA çš„ç»“æ„æ€§ä¿¡æ¯ã€‚

    - A_candidate: å€™é€‰è§£é‚»æ¥çŸ©é˜µï¼ˆå½¢çŠ¶ [d, d]ï¼ŒæŒ‰å˜é‡é¡ºåºï¼‰
    - blacklist: ä¸èƒ½å‡ºç°çš„æœ‰å‘è¾¹é›†åˆï¼ˆæ¥è‡ª yaml ç¡¬çº¦æŸï¼‰
    - whitelist: å¿…é¡»å‡ºç°çš„è¾¹é›†åˆï¼ˆæ¥è‡ª yaml ç¡¬çº¦æŸï¼‰
    - edge_pref: è¾¹åå¥½æƒé‡ Î±_ijï¼Œå½¢çŠ¶åŒ A_candidateï¼ˆå®Œå…¨ç”± LimiX å­¦ä¹ ï¼‰
    - groups: ç»„/å±‚çº§ç¨€ç–ä¿¡æ¯ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ç»„è¾¹çš„ç´¢å¼•åˆ—è¡¨
              ï¼ˆä¾‹å¦‚åŒä¸€ reward æ—ï¼Œæˆ– r_i -> r_j è¿™ç§æ¨¡å¼ï¼‰
    """

    var_names: List[str]
    A_candidate: np.ndarray
    blacklist: List[Edge]
    whitelist: List[Edge]
    edge_pref: np.ndarray
    groups: List[List[Tuple[int, int]]]


def build_default_hard_constraints(var_names: List[str]) -> List[Edge]:
    """
    æ ¹æ®åˆ—åè‡ªåŠ¨ç”Ÿæˆ"å¿…é¡»æ˜¯ r_* -> score"è¿™ä¸€ç±»ç¡¬çº¦æŸã€‚

    - score æ²¡æœ‰æŒ‡å‘å…¶ä»–å˜é‡çš„å‡ºè¾¹
    - å…è®¸ r_* -> score
    - é»˜è®¤ç¦æ­¢ score -> ä»»ä½• r_*
    """
    blacklist: List[Edge] = []
    if "score" not in var_names:
        return blacklist

    for name in var_names:
        if name != "score":
            blacklist.append(("score", name))  # ç¦æ­¢ score ä½œä¸ºçˆ¶ç»“ç‚¹
    return blacklist


def _try_build_edge_pref_with_limix(
    data_csv_dir: Path,
    var_names: List[str],
    edge_pref: np.ndarray,
) -> None:
    """
    ä½¿ç”¨æœ¬åœ° LimiX-2M æ¨¡å‹ï¼ŒåŸºäºæ•°æ®å­¦ä¹  soft priorï¼ˆedge_prefï¼‰ã€‚

    å­¦ä¹ å†…å®¹ï¼š
    1. r_* -> score çš„ soft priorï¼š
       - ç”¨ LimiX-2M å¯¹ score åšå›å½’
       - è®¡ç®—æ¯ä¸ª r_* ç‰¹å¾ä¸é¢„æµ‹ score çš„ç›¸å…³æ€§
       - é‡è¦æ€§è¶Šå¤§ï¼Œå¯¹åº” r_* -> score çš„æƒ©ç½šè¶Šå°

    2. r_i -> r_j çš„ soft priorï¼š
       - è®¡ç®—æ•°æ®ä¸­ r_* ä¹‹é—´çš„ç›¸å…³æ€§
       - ç›¸å…³æ€§è¶Šå¤§ï¼Œå¯¹åº” r_i -> r_j çš„æƒ©ç½šè¶Šå°
       - ä¸é™åˆ¶æ–¹å‘ï¼ŒDAGMA å¯ä»¥è‡ªç”±å­¦ä¹  r_i -> r_j æˆ– r_j -> r_i

    æ³¨æ„ï¼š
    - å¦‚æœä»»ä½•ä¸€æ­¥å¤±è´¥ï¼ˆä¾‹å¦‚ LimiX æœªå®‰è£…ã€æ¨¡å‹æ–‡ä»¶ç¼ºå¤±ï¼‰ï¼Œå°†é™é»˜é€€å›ï¼Œä¸æŠ›å¼‚å¸¸ã€‚
    - ä¸ä¼šè¦†ç›–å·²æœ‰çš„ edge_prefï¼ˆä¾‹å¦‚æ¥è‡ªå…¶ä»–æ¥æºï¼‰ï¼Œè€Œæ˜¯åœ¨å…¶åŸºç¡€ä¸Šå åŠ ã€‚
    """
    try:
        # 1. å‡†å¤‡è·¯å¾„ï¼šæœ¬åœ° LimiX ä»“åº“ + æ¨¡å‹ + é…ç½®
        root_dir = Path("/workspace/LimiX").resolve()
        model_path = root_dir / "cache" / "LimiX-2M.ckpt"
        
        # æ ¹æ®è®¾å¤‡é€‰æ‹©é…ç½®æ–‡ä»¶ï¼šCPU ä¸æ”¯æŒ retrievalï¼Œéœ€è¦ä½¿ç”¨ noretrieval
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        if device.type == "cpu":
            config_path = root_dir / "config" / "reg_default_noretrieval.json"
            print("\n[LimiX] æ£€æµ‹åˆ° CPU è®¾å¤‡ï¼Œä½¿ç”¨ noretrieval é…ç½®")
        else:
            config_path = root_dir / "config" / "reg_default_2M_retrieval.json"
            print("\n[LimiX] æ£€æµ‹åˆ° GPU è®¾å¤‡ï¼Œä½¿ç”¨ retrieval é…ç½®")

        print("[LimiX] å¼€å§‹åŠ è½½æ¨¡å‹...")
        print(f"  æ¨¡å‹è·¯å¾„: {model_path}")
        print(f"  é…ç½®è·¯å¾„: {config_path}")
        
        if not model_path.exists():
            print(f"  âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            return
        if not config_path.exists():
            print(f"  âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
            return
        
        print(f"  âœ… æ¨¡å‹æ–‡ä»¶å­˜åœ¨ï¼Œå¤§å°: {model_path.stat().st_size / (1024*1024):.2f} MB")
        print(f"  âœ… é…ç½®æ–‡ä»¶å­˜åœ¨")

        # 2. è¯»å– data.csv
        data_path = Path(data_csv_dir) / "data.csv"
        if not data_path.exists():
            print(f"  âŒ data.csv æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
            return

        print(f"  [LimiX] è¯»å–æ•°æ®æ–‡ä»¶: {data_path}")
        df = pd.read_csv(data_path)
        if "score" not in df.columns:
            print(f"  âŒ data.csv ä¸­æ²¡æœ‰ score åˆ—")
            return

        # å¯¹é½é¡ºåºï¼šæŒ‰ var_names é‡æ–°æ’åºåˆ—ï¼ˆå®‰å…¨èµ·è§ï¼‰
        cols_in_df = [c for c in var_names if c in df.columns]
        df = df[cols_in_df].copy()

        if "score" not in df.columns:
            print(f"  âŒ å¯¹é½åæ²¡æœ‰ score åˆ—")
            return

        print(f"  âœ… æ•°æ®åŠ è½½æˆåŠŸ: {len(df)} è¡Œ, {len(df.columns)} åˆ—")

        # 3. æ„é€ ç‰¹å¾ä¸æ ‡ç­¾
        y = df["score"].to_numpy(dtype=np.float32)
        feature_cols = [c for c in df.columns if c != "score"]
        if not feature_cols:
            print(f"  âŒ æ²¡æœ‰ç‰¹å¾åˆ—ï¼ˆé™¤äº† scoreï¼‰")
            return
        X = df[feature_cols].to_numpy(dtype=np.float32)
        print(f"  âœ… ç‰¹å¾çŸ©é˜µ: {X.shape[0]} æ ·æœ¬, {X.shape[1]} ç‰¹å¾")

        # 4. å¯¼å…¥ LimiX çš„ LimiXPredictorï¼ˆç¦»çº¿æ¨¡å¼ï¼Œåªç”¨æœ¬åœ° ckptï¼‰
        if str(root_dir) not in sys.path:
            sys.path.insert(0, str(root_dir))

        try:
            from inference.predictor import LimiXPredictor  # type: ignore
        except ImportError as e:
            print(f"  âŒ æ— æ³•å¯¼å…¥ LimiXPredictor: {e}")
            print(f"  ğŸ’¡ æç¤º: éœ€è¦å®‰è£… kditransform ä¾èµ–")
            print(f"     è¿è¡Œ: pip install kditransform")
            print(f"     æˆ–è€…å®‰è£…å®Œæ•´ä¾èµ–: pip install kditransform hyperopt")
            print(f"  âš ï¸  å°†è·³è¿‡ LimiX å­¦ä¹ ï¼Œåªä½¿ç”¨ç¡¬çº¦æŸ")
            return
        except Exception as e:
            print(f"  âŒ æ— æ³•å¯¼å…¥ LimiXPredictor: {e}")
            print(f"  âš ï¸  å°†è·³è¿‡ LimiX å­¦ä¹ ï¼Œåªä½¿ç”¨ç¡¬çº¦æŸ")
            return

        # device å·²ç»åœ¨ä¸Šé¢å®šä¹‰äº†ï¼Œè¿™é‡Œåªæ˜¯æ‰“å°
        print(f"  ä½¿ç”¨è®¾å¤‡: {device}")

        print("  [LimiX] æ­£åœ¨åˆå§‹åŒ–é¢„æµ‹å™¨...")
        predictor = LimiXPredictor(
            device=device,
            model_path=str(model_path),
            inference_config=str(config_path),
            mask_prediction=False,
            inference_with_DDP=False,
        )
        print("  âœ… LimiX æ¨¡å‹åŠ è½½æˆåŠŸï¼")

        # 5. ä½¿ç”¨ LimiX åšä¸€æ¬¡ score å›å½’
        #    ç®€åŒ–å¤„ç†ï¼šç”¨å…¨éƒ¨æ•°æ®åŒæ—¶ä½œä¸º train/testï¼Œåªä¸ºå¾—åˆ° y_hatã€‚
        print(f"  [LimiX] å¼€å§‹å›å½’é¢„æµ‹ (æ ·æœ¬æ•°: {X.shape[0]}, ç‰¹å¾æ•°: {X.shape[1]})...")
        y_pred = predictor.predict(X, y, X, task_type="Regression")
        print("  âœ… LimiX å›å½’é¢„æµ‹å®Œæˆ")

        # LimiX å›å½’è¾“å‡ºé€šå¸¸æ˜¯ torch.Tensorï¼Œå½¢çŠ¶ [n_samples, 1] æˆ– [n_samples]
        if isinstance(y_pred, tuple):
            y_pred = y_pred[0]
        if hasattr(y_pred, "detach"):
            y_pred = y_pred.detach().cpu().numpy()
        y_pred = np.asarray(y_pred).reshape(-1)

        if y_pred.shape[0] != X.shape[0]:
            return

        # 6. è®¡ç®—æ¯ä¸ªç‰¹å¾ä¸é¢„æµ‹ score çš„ç›¸å…³æ€§ï¼Œä½œä¸ºé‡è¦æ€§
        print("  [LimiX] è®¡ç®—ç‰¹å¾é‡è¦æ€§...")
        n_features = X.shape[1]
        importance = np.zeros(n_features, dtype=np.float32)
        for j in range(n_features):
            xj = X[:, j]
            if np.allclose(xj, xj[0]):
                importance[j] = 0.0
                continue
            corr = np.corrcoef(xj, y_pred)[0, 1]
            if np.isnan(corr):
                corr = 0.0
            importance[j] = abs(float(corr))

        max_imp = float(importance.max())
        if max_imp <= 0.0:
            print("  âš ï¸  æ‰€æœ‰ç‰¹å¾é‡è¦æ€§ä¸º0ï¼Œè·³è¿‡")
            return

        importance = importance / (max_imp + 1e-8)

        # æ‰“å° Top 5 é‡è¦ç‰¹å¾
        importance_list = [(feat, imp) for feat, imp in zip(feature_cols, importance)]
        importance_list.sort(key=lambda x: x[1], reverse=True)
        print(f"  Top 5 é‡è¦ç‰¹å¾:")
        for feat, imp in importance_list[:5]:
            print(f"    {feat}: {imp:.4f}")

        # 7. å°†é‡è¦æ€§æ˜ å°„åˆ° edge_prefï¼šr_* -> score è¾¹
        name_to_idx = {name: i for i, name in enumerate(var_names)}
        if "score" not in name_to_idx:
            return
        score_idx = name_to_idx["score"]

        r_to_score_count = 0
        for feat_name, imp in zip(feature_cols, importance):
            if not feat_name.startswith("r_"):
                continue
            if feat_name not in name_to_idx:
                continue
            i = name_to_idx[feat_name]
            # æƒ©ç½šæƒé‡ï¼š1 - importanceï¼Œé‡è¦æ€§è¶Šå¤§ï¼Œæƒ©ç½šè¶Šå°
            weight = 1.0 - float(imp)
            # åœ¨åŸæœ‰ edge_pref åŸºç¡€ä¸Šå åŠ 
            edge_pref[i, score_idx] += weight
            r_to_score_count += 1
        
        print(f"  âœ… å·²å­¦ä¹  {r_to_score_count} æ¡ r_* -> score çš„ soft prior")

        # 8. å­¦ä¹  r_i -> r_j çš„ soft priorï¼šåŸºäº r_* ä¹‹é—´çš„ç›¸å…³æ€§
        print("  [LimiX] è®¡ç®— r_* ä¹‹é—´çš„ç›¸å…³æ€§...")
        r_names = [name for name in var_names if name.startswith("r_")]
        if len(r_names) >= 2:
            r_df = df[r_names].copy()
            r_mat = r_df.to_numpy(dtype=np.float32)
            # è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ
            corr_mat = np.corrcoef(r_mat, rowvar=False)
            corr_mat = np.abs(corr_mat)  # åªå…³å¿ƒç›¸å…³æ€§å¼ºåº¦ï¼Œä¸å…³å¿ƒæ­£è´Ÿ
            np.fill_diagonal(corr_mat, 0.0)  # è‡ªå·±åˆ°è‡ªå·±çš„ç›¸å…³æ€§è®¾ä¸º 0

            max_corr = float(corr_mat.max())
            if max_corr > 0.0:
                corr_norm = corr_mat / (max_corr + 1e-8)
                
                # å¯¹æ¯ä¸€å¯¹ r_i, r_jï¼Œç»™ä¸¤ä¸ªæ–¹å‘éƒ½åŠ ä¸Š soft prior
                # ï¼ˆä¸é™åˆ¶æ–¹å‘ï¼Œè®© DAGMA è‡ªå·±å†³å®šï¼‰
                r_to_r_count = 0
                for a, ra in enumerate(r_names):
                    for b, rb in enumerate(r_names):
                        if a == b:
                            continue
                        imp_ij = float(corr_norm[a, b])
                        if imp_ij > 0.1:  # åªè®°å½•ç›¸å…³æ€§è¾ƒå¼ºçš„
                            w_ij = 1.0 - imp_ij  # ç›¸å…³æ€§è¶Šå¤§ï¼Œæƒ©ç½šè¶Šå°
                            ia = name_to_idx.get(ra)
                            jb = name_to_idx.get(rb)
                            if ia is None or jb is None:
                                continue
                            # å¯¹ä¸¤ä¸ªæ–¹å‘éƒ½åŠ ä¸Š soft priorï¼ˆè®© DAGMA è‡ªå·±é€‰æ‹©æ–¹å‘ï¼‰
                            edge_pref[ia, jb] += w_ij
                            r_to_r_count += 1
                            # æ³¨æ„ï¼šè¿™é‡Œä¹Ÿå¯ä»¥åªåŠ ä¸€ä¸ªæ–¹å‘ï¼Œçœ‹ä½ çš„éœ€æ±‚
                            # å¦‚æœåªæƒ³è¦å•å‘ï¼Œå¯ä»¥æ³¨é‡Šæ‰ä¸‹é¢è¿™è¡Œ
                            # edge_pref[jb, ia] += w_ij
                
                print(f"  âœ… å·²å­¦ä¹  {r_to_r_count} æ¡ r_i -> r_j çš„ soft prior (ç›¸å…³æ€§ > 0.1)")
            else:
                print("  âš ï¸  r_* ä¹‹é—´æ²¡æœ‰ç›¸å…³æ€§ï¼Œè·³è¿‡")
        else:
            print(f"  âš ï¸  r_* å˜é‡æ•°é‡ä¸è¶³ ({len(r_names)} < 2)ï¼Œè·³è¿‡ r_i -> r_j å­¦ä¹ ")
        
        print("[LimiX] âœ… å­¦ä¹ å®Œæˆï¼\n")

    except Exception as e:
        # æ‰“å°é”™è¯¯ä¿¡æ¯ï¼Œæ–¹ä¾¿è°ƒè¯•
        print(f"[LimiX] âŒ å­¦ä¹ è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return


def run_limix_ldm_placeholder(
    data_csv_dir: str | Path,
    var_names: List[str],
) -> LimixConstraints:
    """
    æ•´åˆ LimiX æ¨¡å‹è¾“å‡ºå’Œ yaml ç¡¬çº¦æŸï¼Œç”Ÿæˆä¼ ç»™ DAGMA çš„çº¦æŸé›†åˆã€‚

    é€»è¾‘ï¼š
    1. ç¡¬çº¦æŸï¼ˆblacklist/whitelistï¼‰ï¼šå®Œå…¨æ¥è‡ª limix_config.yaml
    2. è½¯çº¦æŸï¼ˆedge_prefï¼‰ï¼šå®Œå…¨ç”± LimiX å®˜æ–¹æ¨¡å‹åŸºäºæ•°æ®å­¦ä¹ 
    3. yaml ä¸­çš„ soft_edges ä¸å†ä½¿ç”¨ï¼ˆåªä½œä¸ºæ³¨é‡Šä¿ç•™ï¼‰

    è¿”å›
    ----
    LimixConstraints:
        åŒ…å«å€™é€‰ç»“æ„ã€ç¡¬çº¦æŸã€è½¯çº¦æŸçš„å®Œæ•´çº¦æŸé›†åˆ
    """
    d = len(var_names)
    A_candidate = np.zeros((d, d), dtype=np.float32)
    edge_pref = np.zeros_like(A_candidate)

    # 1. é»˜è®¤ç¡¬çº¦æŸï¼šscore ä¸èƒ½æŒ‡å‘å…¶ä»–å˜é‡
    blacklist: List[Edge] = build_default_hard_constraints(var_names)
    whitelist: List[Edge] = []

    # 2. è¯»å– limix_config.yaml ä¸­çš„ç¡¬çº¦æŸï¼ˆblacklist/whitelistï¼‰
    print("=" * 60)
    print("æ­¥éª¤ 2: è¯»å–ç¡¬çº¦æŸé…ç½®")
    print("=" * 60)
    config_path = Path(data_csv_dir).parent / "limix_config.yaml"
    if config_path.exists():
        print(f"è¯»å–é…ç½®æ–‡ä»¶: {config_path}")
        with open(config_path, "r", encoding="utf-8") as f:
            cfg = yaml.safe_load(f) or {}

        # 2.1 è§£æç¡¬çº¦æŸï¼ˆé»‘åå• / ç™½åå•ï¼‰
        hard = (cfg.get("hard_edges") or {})
        for item in hard.get("blacklist", []) or []:
            try:
                u, v = [s.strip() for s in item.split("->")]
                blacklist.append((u, v))
            except Exception:
                # æ ¼å¼é”™è¯¯æ—¶å¿½ç•¥è¯¥æ¡
                pass

        for item in hard.get("whitelist", []) or []:
            try:
                # æ”¯æŒä¸¤ç§æ ¼å¼ï¼š
                # 1. å­—ç¬¦ä¸²æ ¼å¼: "r_pos_reward -> score"
                # 2. å­—å…¸æ ¼å¼: {edge: "r_pos_reward -> score", alpha: 1.0}
                if isinstance(item, str):
                    u, v = [s.strip() for s in item.split("->")]
                    whitelist.append((u, v))
                elif isinstance(item, dict):
                    edge_str = item.get("edge", "")
                    if edge_str:
                        u, v = [s.strip() for s in edge_str.split("->")]
                        whitelist.append((u, v))
            except Exception:
                pass

        print(f"  é»‘åå• (blacklist): {len(blacklist)} æ¡")
        if blacklist:
            for u, v in blacklist[:5]:  # åªæ˜¾ç¤ºå‰5æ¡
                print(f"    {u} -> {v}")
            if len(blacklist) > 5:
                print(f"    ... è¿˜æœ‰ {len(blacklist) - 5} æ¡")
        
        print(f"  ç™½åå• (whitelist): {len(whitelist)} æ¡")
        if whitelist:
            for u, v in whitelist[:5]:  # åªæ˜¾ç¤ºå‰5æ¡
                print(f"    {u} -> {v}")
            if len(whitelist) > 5:
                print(f"    ... è¿˜æœ‰ {len(whitelist) - 5} æ¡")
        
        # 2.2 yaml ä¸­çš„ soft_edges ç°åœ¨åªä½œä¸º"å¯è¡ŒåŸŸæç¤º"ï¼Œ
        #     ä¸å†ç›´æ¥è½¬æˆ edge_prefï¼Œé¿å…äººå·¥è½¯çº¦æŸä¸»å¯¼å­¦ä¹ ï¼›
        #     å…·ä½“ soft prior äº¤ç”±ä¸‹æ–¹ LimiX åŸºäºæ•°æ®è‡ªåŠ¨ç”Ÿæˆã€‚
        # ï¼ˆæ³¨é‡Šæ‰åŸæ¥çš„ soft_edges è§£æä»£ç ï¼‰
    else:
        print(f"âš ï¸  é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}ï¼Œä½¿ç”¨é»˜è®¤ç¡¬çº¦æŸ")

    # 3. ä½¿ç”¨æœ¬åœ° LimiX-2M æ¨¡å‹ï¼ŒåŸºäºæ•°æ®å­¦ä¹  soft priorï¼ˆedge_prefï¼‰
    #    åŒ…æ‹¬ï¼šr_* -> score å’Œ r_i -> r_j çš„ soft prior
    print("=" * 60)
    print("æ­¥éª¤ 3: LimiX å­¦ä¹  soft prior")
    print("=" * 60)
    _try_build_edge_pref_with_limix(Path(data_csv_dir), var_names, edge_pref)
    
    # ä¿å­˜å­¦ä¹ åˆ°çš„ edge_pref çŸ©é˜µä¸º CSV
    output_dir = Path(data_csv_dir).parent / "output"
    output_dir.mkdir(parents=True, exist_ok=True)
    edge_pref_df = pd.DataFrame(edge_pref, index=var_names, columns=var_names)
    edge_pref_csv = output_dir / "limix_edge_pref_matrix.csv"
    edge_pref_df.to_csv(edge_pref_csv)
    print(f"âœ… edge_pref çŸ©é˜µå·²ä¿å­˜åˆ°: {edge_pref_csv}")
    
    # æ‰“å° edge_pref ç»Ÿè®¡ä¿¡æ¯
    non_zero_count = np.count_nonzero(edge_pref)
    print(f"  éé›¶è¾¹æ•°é‡: {non_zero_count} / {edge_pref.size}")
    max_weight = edge_pref.max()
    min_weight = edge_pref.min()
    if non_zero_count > 0:
        avg_weight = edge_pref[edge_pref > 0].mean()
    else:
        avg_weight = 0.0
    print(f"  æœ€å¤§æƒé‡: {max_weight:.4f}, æœ€å°æƒé‡: {min_weight:.4f}, å¹³å‡æƒé‡: {avg_weight:.4f}")

    # 4. ç»„ç¨€ç–ï¼šå°†æ‰€æœ‰ r_* -> score è§†ä½œä¸€ç»„
    groups: List[List[Tuple[int, int]]] = []
    if "score" in var_names:
        score_idx = var_names.index("score")
        group_edges: List[Tuple[int, int]] = []
        for i, name in enumerate(var_names):
            if name.startswith("r_"):
                group_edges.append((i, score_idx))
        if group_edges:
            groups.append(group_edges)

    return LimixConstraints(
        var_names=var_names,
        A_candidate=A_candidate,
        blacklist=blacklist,
        whitelist=whitelist,
        edge_pref=edge_pref,
        groups=groups,
    )


__all__ = ["Edge", "LimixConstraints", "run_limix_ldm_placeholder"]
